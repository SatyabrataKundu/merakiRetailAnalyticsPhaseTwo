{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhadip_jot\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\subhadip_jot\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "C:\\Users\\subhadip_jot\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "C:\\Users\\subhadip_jot\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "#Importing data\n",
    "df = pd.read_csv('1year_hourly_data_2015.csv')\n",
    "# df.describe()\n",
    "\n",
    "#Creating train and test set \n",
    "train=df[0:8755] #80% of data ( 0.8 * 8755 for training the model) \n",
    "test=df[8755:] # remaining 20% to test\n",
    "\n",
    "#Aggregating the dataset at daily level\n",
    "df.Timestamp = pd.to_datetime(df.dateformat_hour,format='%Y-%m-%d %H:%M:%S') \n",
    "df.index = df.Timestamp \n",
    "df = df.resample('H').mean() #daily mean\n",
    "train.Timestamp = pd.to_datetime(train.dateformat_hour,format='%Y-%m-%d %H:%M:%S') \n",
    "train.index = train.Timestamp \n",
    "train = train.resample('H').mean() \n",
    "test.Timestamp = pd.to_datetime(test.dateformat_hour,format='%Y-%m-%d %H:%M:%S') \n",
    "test.index = test.Timestamp \n",
    "test = test.resample('H').mean()\n",
    "\n",
    "y_hat_avg = test.copy()\n",
    "fit1 = sm.tsa.SARIMAX(train, order=(2, 1, 4),seasonal_order=(0,1,1,24)).fit()\n",
    "y_hat_avg['SARIMA'] = predictions = fit1.predict(start=\"2016-1-1 00:00:00\", end=\"2016-1-2 00:00:00\", dynamic=True)\n",
    "\n",
    "predictedValues = list()\n",
    "for t in predictions:\n",
    "    predictedValues.append(math.ceil(t))\n",
    "\n",
    "print(predictedValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    dateformat_hour  count     SARIMA\n",
      "2016-01-01 00:00:00             NaN    NaN   0.418653\n",
      "2016-01-01 01:00:00             NaN    NaN   0.190128\n",
      "2016-01-01 02:00:00             NaN    NaN   0.647254\n",
      "2016-01-01 03:00:00             NaN    NaN   0.834851\n",
      "2016-01-01 04:00:00             NaN    NaN   0.469592\n",
      "2016-01-01 05:00:00             NaN    NaN   0.559740\n",
      "2016-01-01 06:00:00             NaN    NaN   0.396667\n",
      "2016-01-01 07:00:00             NaN    NaN   0.551315\n",
      "2016-01-01 08:00:00             NaN    NaN  42.405452\n",
      "2016-01-01 09:00:00             NaN    NaN  43.573562\n",
      "2016-01-01 10:00:00             NaN    NaN  42.299121\n",
      "2016-01-01 11:00:00             NaN    NaN  43.488346\n",
      "2016-01-01 12:00:00             NaN    NaN  43.691476\n",
      "2016-01-01 13:00:00             NaN    NaN  42.469065\n",
      "2016-01-01 14:00:00             NaN    NaN  43.638139\n",
      "2016-01-01 15:00:00             NaN    NaN  43.344912\n",
      "2016-01-01 16:00:00             NaN    NaN  42.231227\n",
      "2016-01-01 17:00:00             NaN    NaN  43.344612\n",
      "2016-01-01 18:00:00             NaN    NaN  82.514673\n",
      "2016-01-01 19:00:00             NaN    NaN  83.192828\n",
      "2016-01-01 20:00:00             NaN    NaN  42.480914\n",
      "2016-01-01 21:00:00             NaN    NaN  43.375215\n",
      "2016-01-01 22:00:00             NaN    NaN  42.236830\n",
      "2016-01-01 23:00:00             NaN    NaN   0.585914\n",
      "2016-01-02 00:00:00             NaN    NaN   0.540226\n",
      "2016-01-02 01:00:00             NaN    NaN        NaN\n",
      "2016-01-02 02:00:00             NaN    NaN        NaN\n",
      "2016-01-02 03:00:00             NaN    NaN        NaN\n",
      "2016-01-02 04:00:00             NaN    NaN        NaN\n",
      "2016-01-02 05:00:00             NaN    NaN        NaN\n",
      "...                             ...    ...        ...\n",
      "2016-01-29 19:00:00             NaN    NaN        NaN\n",
      "2016-01-29 20:00:00             NaN    NaN        NaN\n",
      "2016-01-29 21:00:00             NaN    NaN        NaN\n",
      "2016-01-29 22:00:00             NaN    NaN        NaN\n",
      "2016-01-29 23:00:00             NaN    NaN        NaN\n",
      "2016-01-30 00:00:00             NaN    NaN        NaN\n",
      "2016-01-30 01:00:00             NaN    NaN        NaN\n",
      "2016-01-30 02:00:00             NaN    NaN        NaN\n",
      "2016-01-30 03:00:00             NaN    NaN        NaN\n",
      "2016-01-30 04:00:00             NaN    NaN        NaN\n",
      "2016-01-30 05:00:00             NaN    NaN        NaN\n",
      "2016-01-30 06:00:00             NaN    NaN        NaN\n",
      "2016-01-30 07:00:00             NaN    NaN        NaN\n",
      "2016-01-30 08:00:00             NaN    NaN        NaN\n",
      "2016-01-30 09:00:00             NaN    NaN        NaN\n",
      "2016-01-30 10:00:00             NaN    NaN        NaN\n",
      "2016-01-30 11:00:00             NaN    NaN        NaN\n",
      "2016-01-30 12:00:00             NaN    NaN        NaN\n",
      "2016-01-30 13:00:00             NaN    NaN        NaN\n",
      "2016-01-30 14:00:00             NaN    NaN        NaN\n",
      "2016-01-30 15:00:00             NaN    NaN        NaN\n",
      "2016-01-30 16:00:00             NaN    NaN        NaN\n",
      "2016-01-30 17:00:00             NaN    NaN        NaN\n",
      "2016-01-30 18:00:00             NaN    NaN        NaN\n",
      "2016-01-30 19:00:00             NaN    NaN        NaN\n",
      "2016-01-30 20:00:00             NaN    NaN        NaN\n",
      "2016-01-30 21:00:00             NaN    NaN        NaN\n",
      "2016-01-30 22:00:00             NaN    NaN        NaN\n",
      "2016-01-30 23:00:00             NaN    NaN        NaN\n",
      "2016-01-31 00:00:00             NaN    NaN        NaN\n",
      "\n",
      "[721 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=merakidb user=postgres password=postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"DELETE FROM meraki.hourly_visitor_predictions\")\n",
    "for i in range(len(predictions)):\n",
    "    hourCount = i+1\n",
    "    visitorCount = math.ceil(predictions[i])\n",
    "    cur.execute(\"INSERT INTO meraki.hourly_visitor_predictions (dateformat_hour,count) VALUES (%s, %s);\", (hourCount, visitorCount))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhadip_jot\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\subhadip_jot\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "C:\\Users\\subhadip_jot\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "C:\\Users\\subhadip_jot\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[691, 1034, 1028, 703, 707, 705]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 3118\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   3119\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 6",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4ae678b62361>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mdayCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mvisitorCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INSERT INTO meraki.daily_visitor_predictions (dateformat_day,count) VALUES (%s, %s);\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdayCount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisitorCount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1563\u001b[1;33m             return com._maybe_box(self, Index.get_value(self, series, key),\n\u001b[0m\u001b[0;32m   1564\u001b[0m                                   series, key)\n\u001b[0;32m   1565\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   3122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3123\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3124\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3125\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3126\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "#Importing data\n",
    "df = pd.read_csv('1year_hourly_data_2015.csv')\n",
    "# df.describe()\n",
    "\n",
    "#Creating train and test set \n",
    "train=df[0:8755] #80% of data ( 0.8 * 8755 for training the model) \n",
    "test=df[8755:] # remaining 20% to test\n",
    "\n",
    "#Aggregating the dataset at daily level\n",
    "df.Timestamp = pd.to_datetime(df.dateformat_hour,format='%Y-%m-%d %H:%M:%S') \n",
    "df.index = df.Timestamp \n",
    "df = df.resample('D').sum() #daily mean\n",
    "train.Timestamp = pd.to_datetime(train.dateformat_hour,format='%Y-%m-%d %H:%M:%S') \n",
    "train.index = train.Timestamp \n",
    "train = train.resample('D').sum() \n",
    "test.Timestamp = pd.to_datetime(test.dateformat_hour,format='%Y-%m-%d %H:%M:%S') \n",
    "test.index = test.Timestamp \n",
    "test = test.resample('D').sum()\n",
    "\n",
    "y_hat_avg = test.copy()\n",
    "fit1 = sm.tsa.SARIMAX(train, order=(2, 1, 4),seasonal_order=(0,1,1,7)).fit()\n",
    "y_hat_avg['SARIMA'] = predictions = fit1.predict(start=\"2016-1-1\", end=\"2016-1-6\", dynamic=True)\n",
    "\n",
    "predictedValues = list()\n",
    "for t in predictions:\n",
    "    predictedValues.append(math.ceil(t))\n",
    "\n",
    "print(predictedValues)\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=merakidb user=postgres password=postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"DELETE FROM meraki.daily_visitor_predictions\")\n",
    "for i in range(0, 7):\n",
    "    dayCount = i+1\n",
    "    visitorCount = math.ceil(predictions[i])\n",
    "    cur.execute(\"INSERT INTO meraki.daily_visitor_predictions (dateformat_day,count) VALUES (%s, %s);\", (dayCount, visitorCount))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
